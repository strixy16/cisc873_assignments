{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fk8pTqLXOXZ"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_7L7RfON32v"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2dCmRiUStc9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, Input, MaxPool2D\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDOQfl9oXRB_"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNcKc32RS7PI"
      },
      "outputs": [],
      "source": [
        "def load_data(folder):\n",
        "    images = []\n",
        "    for file in os.listdir(folder):\n",
        "        file_id = file.replace('.png', '')\n",
        "        image = Image.open(\n",
        "            os.path.join(folder, file)\n",
        "        ).convert('LA').resize((256, 256))\n",
        "        arr = np.array(image)\n",
        "        images.append(\n",
        "            (int(file_id), arr)\n",
        "        )\n",
        "    images.sort(key=lambda i: i[0])\n",
        "    return np.array([v for _id, v in images])\n",
        "\n",
        "\n",
        "x_train = load_data('drive/My Drive/873/train')\n",
        "y_train = pd.read_csv('drive/My Drive/873/y_train.csv')['infection']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3a7KbTz701E"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQ3tPPI8UYBz"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iro1kV0wIdGk"
      },
      "source": [
        "*Note: if a layer is used in multiple models, it is only explained in the comments the first time it appears.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKPEPmOWo4-d"
      },
      "source": [
        "## Fully Connected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R35rvzJoTcWY"
      },
      "outputs": [],
      "source": [
        "# Fully connected model 1 (given in example code)\n",
        "def build_FC1():\n",
        "    # Tensor object for images\n",
        "    img_in = Input(shape=(256, 256, 2)) # [None, 256, 256, 2]\n",
        "    # Flattens tensor to vector\n",
        "    flattened = Flatten()(img_in) # [None, 131,072]\n",
        "    # Fully connected layer with 64 units\n",
        "    x = Dense(64)(flattened) # [None, 64]\n",
        "    # Fully connected layer with 32 units\n",
        "    x = Dense(32)(x) # [None, 32]\n",
        "    \n",
        "    # Output layer, sigmoid activation\n",
        "    output = Dense(1, activation = 'sigmoid')(x) # [None, 1]\n",
        "    # Create the model\n",
        "    model = Model(inputs=img_in, outputs=output, name=\"fc1\")\n",
        "    return model\n",
        "\n",
        "\n",
        "model = build_FC1()\n",
        "# Compile model with\n",
        "#   - Adam optimizer\n",
        "#   - Binary Cross entropy loss - used for binary classification\n",
        "#   - Binary accuracy and AUC evaluation metrics\n",
        "model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['BinaryAccuracy', 'AUC']\n",
        "        )\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4x2QdgTUWTN"
      },
      "outputs": [],
      "source": [
        "# Fully connected model 2 (given in example code)\n",
        "# Using dropout layers => randomly set input units to 0 at each step during training\n",
        "# Version 1: Input -> Flatten -> Dense64 -> Dropout(0.3) -> Dense32 -> Dropout(0.3) -> Ouput\n",
        "# Version 2: increase dropout rate to 0.5\n",
        "# Version 3: increase dropout rate to 0.8 \n",
        "def build_FC2():\n",
        "    img_in = Input(shape=(256, 256, 2)) # [None, 256, 256, 2]\n",
        "    flattened = Flatten()(img_in) # [None, 131072]\n",
        "    x = Dense(64)(flattened) # [None, 64]\n",
        "    # Dropout layer with 0.8 rate\n",
        "    x = Dropout(0.8)(x) # [None, 64]\n",
        "    x = Dense(32)(x) # [None, 32]\n",
        "    # Dropout layer with 0.8 rate\n",
        "    x = Dropout(0.8)(x) # [None, 32]\n",
        "    \n",
        "    output = Dense(1, activation = 'sigmoid')(x) # [None, 1]\n",
        "    model = Model(inputs=img_in, outputs=output, name=\"fc2_3\")\n",
        "    return model\n",
        "\n",
        "model = build_FC2()\n",
        "model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss='binary_crossentropy',\n",
        "        # Evaluating matches with two metrics\n",
        "        metrics=['BinaryAccuracy', 'AUC']\n",
        "        )\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEDHs6XnfBwd"
      },
      "outputs": [],
      "source": [
        "# Fully connected model 3\n",
        "# Exploring adding layers\n",
        "# Version 1: adding a Dense16 layer after the 32 and another dropout\n",
        "#  Input -> Flatten -> Dense64 -> Dropout -> Dense32 -> Dropout -> Dense16 -> Dropout -> Output \n",
        "# Version 2: increase dropout to 0.8 \n",
        "# Version 3: moved extra layer to the front, made it 128 nodes, back to 0.5 dropout\n",
        "# Version 4: adding another layer to the front, doubling size again\n",
        "def build_FC3():\n",
        "    img_in = Input(shape=(256, 256, 2)) # [None, 256, 256, 2]\n",
        "    flattened = Flatten()(img_in) # [None, 131072]\n",
        "    # Added next dense and dropout in version 4\n",
        "    x = Dense(256)(flattened) # [None, 256]\n",
        "    x = Dropout(0.5)(x) # [None, 256]\n",
        "    # Added next dense and dropout in version 3\n",
        "    x = Dense(128)(x) # [None, 128]\n",
        "    x = Dropout(0.5)(x) # [None, 128]\n",
        "    \n",
        "    x = Dense(64)(x) # [None, 64]\n",
        "    # Changed from 0.5 to 0.8 in version 2 and back to 0.5 in version 3\n",
        "    x = Dropout(0.5)(x) # [None, 64]\n",
        "    x = Dense(32)(x) # [None, 32]\n",
        "    # Changed from 0.5 to 0.8 in version 2 and back to 0.5 in version 3\n",
        "    x = Dropout(0.5)(x) # [None, 32]\n",
        "\n",
        "    # Added in version 1, removed in version 3\n",
        "    # x = Dense(16)(x) # [None, 16]\n",
        "    # Changed from 0.5 to 0.8 in version 2\n",
        "    # x = Dropout(0.5)(x) # [None, 16]\n",
        "\n",
        "    output = Dense(1, activation = 'sigmoid')(x) # [None, 1]\n",
        "    model = Model(inputs=img_in, outputs=output, name=\"fc3_5\")\n",
        "    return model\n",
        "\n",
        "model = build_FC3()\n",
        "model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss='binary_crossentropy',\n",
        "        # Evaluating matches with two metrics\n",
        "        metrics=['BinaryAccuracy', 'AUC']\n",
        "        )\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIDW8QNGxmlM"
      },
      "outputs": [],
      "source": [
        "# Fully connected model 4\n",
        "# Exploring activation functions\n",
        "# Version 1: using softmax on all hidden layers\n",
        "# Version 2: tanh activation on all hidden layers\n",
        "# Version 3: relu activation on all hidden layers\n",
        "# Version 4: relu, no dropout\n",
        "def build_FC4():\n",
        "    img_in = Input(shape=(256, 256, 2)) # [None, 256, 256, 2]\n",
        "    flattened = Flatten()(img_in) # [None, 131072]\n",
        "\n",
        "    x = Dense(128, activation='relu')(flattened) # [None, 128]\n",
        "    # Removed in version 4\n",
        "    # x = Dropout(0.5)(x) # [None, 128]\n",
        "    x = Dense(64, activation='relu')(x) # [None, 64]\n",
        "    # Removed in version 4\n",
        "    # x = Dropout(0.5)(x) # [None, 64]\n",
        "    x = Dense(32, activation='relu')(x) # [None, 32]\n",
        "    # Removed in version 4\n",
        "    # x = Dropout(0.5)(x) # [None, 32]\n",
        "\n",
        "    output = Dense(1, activation = 'sigmoid')(x) # [None, 1]\n",
        "    model = Model(inputs=img_in, outputs=output, name=\"fc4_4\")\n",
        "    return model\n",
        "\n",
        "model = build_FC4()\n",
        "model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss='binary_crossentropy',\n",
        "        # Evaluating matches with two metrics\n",
        "        metrics=['BinaryAccuracy', 'AUC']\n",
        "        )\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV53TGPV5HQx"
      },
      "outputs": [],
      "source": [
        "# Fully connected model 5\n",
        "# Using fully connected model (fc3_3) with highest test score so far to test out \n",
        "# different optimizers\n",
        "# Version 1: RMS Prop\n",
        "# Version 2: Adagrad with learning rate = 0.001\n",
        "# Version 3: Adagrad with learning rate = 0.0001 \n",
        "def build_FC5():\n",
        "    img_in = Input(shape=(256, 256, 2)) # [None, 256, 256, 2]\n",
        "\n",
        "    flattened = Flatten()(img_in) # [None, 131072]\n",
        "    x = Dense(128)(flattened) # [None, 128]\n",
        "    x = Dropout(0.5)(x) # [None, 128]\n",
        "    x = Dense(64)(x) # [None, 64]\n",
        "    x = Dropout(0.5)(x) # [None, 64]\n",
        "    x = Dense(32)(x) # [None, 32]\n",
        "    x = Dropout(0.5)(x) # [None, 32]\n",
        "\n",
        "    output = Dense(1, activation = 'sigmoid')(x) # [None, 1]\n",
        "    model = Model(inputs=img_in, outputs=output, name=\"fc5_3\")\n",
        "    return model\n",
        "\n",
        "model = build_FC5()\n",
        "model.compile(\n",
        "        # optimizer = tf.keras.optimizers.RMSprop(),\n",
        "        optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        # Evaluating matches with two metrics\n",
        "        metrics=['BinaryAccuracy', 'AUC']\n",
        "        )\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4xj-iIao_bu"
      },
      "source": [
        "## Convolutional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moppoklZMYO4"
      },
      "outputs": [],
      "source": [
        "# Convolutional model 1\n",
        "# Version 1: Single conv2 and pool layer, padding = 'valid'\n",
        "# Version 2: Increasing number of filters to be conv8\n",
        "# Version 3: conv16\n",
        "# Version 4: conv8, padding = 'same'\n",
        "# Version 5: kernel_size = 5\n",
        "def build_conv1():\n",
        "    # Tensor object for images\n",
        "    img_in = Input(shape=(256,256,2)) # [None, 256, 256, 2]\n",
        "\n",
        "    # Convolutional layer, 8 filters of size 5x5, with padding to make output \n",
        "    # the same size as input, using rectified linear unit activation function\n",
        "    # which takes the max(x, 0)\n",
        "    x = Conv2D(filters=8, kernel_size=5, activation='relu', padding='same')(img_in) # [None, 256, 256, 8]\n",
        "    # Max pooling layer, taking max value over 2x2 window \n",
        "    x = MaxPool2D(pool_size=(2,2))(x) # [None, 128, 128, 8]\n",
        "\n",
        "    # Flattens tensor to vector\n",
        "    x = Flatten()(x) # [None, 131072]\n",
        "    output = Dense(1, activation='sigmoid')(x) # [None, 1]\n",
        "\n",
        "    model = Model(inputs=img_in, outputs=output, name=\"conv1_5\")\n",
        "    return model\n",
        "\n",
        "model = build_conv1()\n",
        "model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['BinaryAccuracy', 'AUC']\n",
        ")\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkl7JfwHIF4c"
      },
      "outputs": [],
      "source": [
        "# Convolutional model 2\n",
        "# Adding more layers\n",
        "# Version 1: Adding another identical conv8 and pool layer\n",
        "# Version 2: Making first layer have more filters => conv16\n",
        "# Version 3: Added conv32 + pool\n",
        "# Version 4: Added conv64 + pool\n",
        "# Version 5: Added conv128 + pool\n",
        "def build_conv2():\n",
        "    img_in = Input(shape=(256,256,2)) # [None, 256, 256, 2]\n",
        "    x = Conv2D(filters=128, kernel_size=3, activation='relu', padding='same')(img_in) # [None, 256, 256, 128]\n",
        "    x = MaxPool2D(pool_size=(2,2))(x) # [None, 128, 128, 128]\n",
        "\n",
        "    x = Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(x) # [None, 128, 128, 64]\n",
        "    x = MaxPool2D(pool_size=(2,2))(x) # [None, 64, 64, 64]\n",
        "\n",
        "    x = Conv2D(filters=32, kernel_size=3, activation='relu', padding='same')(x) # [None, 64, 64, 32]\n",
        "    x = MaxPool2D(pool_size=(2,2))(x) # [None, 32, 32, 32]\n",
        "\n",
        "    x = Conv2D(filters=16, kernel_size=3, activation='relu', padding='same')(x) # [None, 32, 32, 16]\n",
        "    x = MaxPool2D(pool_size=(2,2))(x) # [None, 16, 16, 16]\n",
        "\n",
        "    x = Conv2D(filters=8, kernel_size=3, activation='relu', padding='same')(x) # [None, 16, 16, 8]\n",
        "    x = MaxPool2D(pool_size=(2,2))(x) # [None, 8, 8, 8]\n",
        "\n",
        "    # Flattens tensor to vector\n",
        "    x = Flatten()(x) # [None, 512]\n",
        "    output = Dense(1, activation='sigmoid')(x) # [None, 1]\n",
        "\n",
        "    model = Model(inputs=img_in, outputs=output, name=\"conv2_5\")\n",
        "    return model\n",
        "\n",
        "model = build_conv2()\n",
        "model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['BinaryAccuracy', 'AUC']\n",
        ")\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZhLgh5VQOTR"
      },
      "outputs": [],
      "source": [
        "# Convolutional model 3\n",
        "# Trying different layer arrangement\n",
        "# Version 1: Rearragned layers to be CONV => CONV => POOL => CONV => CONV => POOL \n",
        "def build_conv3():\n",
        "    img_in = Input(shape=(256,256,2)) # [None, 256, 256, 2]\n",
        "\n",
        "    x = Conv2D(filters=64, kernel_size=3, activation='relu', padding='same')(img_in) # [None, 256, 256, 64]\n",
        "    x = Conv2D(filters=32, kernel_size=3, activation='relu', padding='same')(x) # [None, 256, 256, 32]\n",
        "    x = MaxPool2D(pool_size=(2,2))(x) # [None, 128, 128, 32]\n",
        "\n",
        "    x = Conv2D(filters=16, kernel_size=3, activation='relu', padding='same')(x) # [None, 128, 128, 16]\n",
        "    x = Conv2D(filters=8, kernel_size=3, activation='relu', padding='same')(x) # [None, 128, 128, 8]\n",
        "    x = MaxPool2D(pool_size=(2,2))(x) # [None, 64, 64, 8]\n",
        "\n",
        "    # Flattens tensor to vector\n",
        "    x = Flatten()(x) # [None, 32768]\n",
        "    output = Dense(1, activation='sigmoid')(x) # [None, 1]\n",
        "\n",
        "    model = Model(inputs=img_in, outputs=output, name=\"conv3_1\")\n",
        "    return model\n",
        "\n",
        "model = build_conv3()\n",
        "model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['BinaryAccuracy', 'AUC']\n",
        ")\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zx4Z9NQTjKOE"
      },
      "outputs": [],
      "source": [
        "# Convolutional Model 4\n",
        "# Using convolutional model (conv1_4) with highest test score so far to test out \n",
        "# different optimizers\n",
        "# Version 1: Uses RMS Prop\n",
        "# Version 2: Adagrad with learning rate = 0.001\n",
        "# Version 3: Adagrad with learning rate = 0.0001\n",
        "def build_conv4():\n",
        "    img_in = Input(shape=(256,256,2)) # [None, 256, 256, 2]\n",
        "    x = Conv2D(filters=8, kernel_size=3, activation='relu', padding='same')(img_in) # [None, 128, 128, 8]\n",
        "    x = MaxPool2D(pool_size=(2,2))(x) # [None, 128, 128, 8]\n",
        "    x = Flatten()(x) # [None, 131072]\n",
        "    output = Dense(1, activation='sigmoid')(x) # [None, 1]\n",
        "\n",
        "    model = Model(inputs=img_in, outputs=output, name=\"conv4\")\n",
        "    return model\n",
        "\n",
        "model = build_conv4()\n",
        "model.compile(\n",
        "        # optimizer = tf.keras.optimizers.RMSprop(),\n",
        "        optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.0001),\n",
        "        loss='binary_crossentropy',\n",
        "        # Evaluating matches with two metrics\n",
        "        metrics=['BinaryAccuracy', 'AUC']\n",
        ")\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzpoq3oFOu7d"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "995mCsStTuxv"
      },
      "outputs": [],
      "source": [
        "# MODEL TRAINING\n",
        "print(\"Training model: \" + model.name)\n",
        "# Number of forward and backward passes to perform through network\n",
        "epochs = 30\n",
        "# Number of training examples to use in one iteration\n",
        "batch_size = 32\n",
        "history = model.fit(x = x_train,\n",
        "                    y = y_train,\n",
        "                    batch_size = batch_size,\n",
        "                    # fraction of training data hold out as validation data (30%)\n",
        "                    validation_split=0.3,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4cGay1LFqlV"
      },
      "outputs": [],
      "source": [
        "# Create AUC metric vs. epoch plot\n",
        "plt.plot(history.history['auc'])\n",
        "plt.plot(history.history['val_auc'])\n",
        "plt.title('model accuracy - ' + model.name)\n",
        "plt.ylabel('AUC')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFbbRPlhXIUN"
      },
      "source": [
        "# Output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWb-GbGKT2pf"
      },
      "outputs": [],
      "source": [
        "# LOAD TEST DATA\n",
        "x_test = load_data('drive/My Drive/873/test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K1ztouoTyVU"
      },
      "outputs": [],
      "source": [
        "# MODEL TESTING\n",
        "y_test = model.predict(x_test)\n",
        "\n",
        "output_name = model.name + '_' + str(epochs) + '_' + str(batch_size) + '.csv'\n",
        "\n",
        "y_test_df = pd.DataFrame()\n",
        "y_test_df['id'] = np.arange(len(y_test))\n",
        "y_test_df['infection'] = y_test.astype(float)\n",
        "y_test_df.to_csv(output_name, index=False)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Code",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
