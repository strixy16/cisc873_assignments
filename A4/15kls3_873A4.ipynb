{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "name": "Code.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6lY7a6S4v3Dx"
      ]
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "164182fe6aed4ba68c567a0e3914fab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_77d639ca2913440885008a08dddd5aeb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9dc601469c85439f90d72ab941c44c84",
              "IPY_MODEL_cb33613314e9467dbb2e61f5eb0491d6"
            ]
          }
        },
        "77d639ca2913440885008a08dddd5aeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9dc601469c85439f90d72ab941c44c84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_87e2f11c782d48b0885d7db9151908e4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7360,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7360,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77dfbcedf5224ae9847aaf7e7268b9a3"
          }
        },
        "cb33613314e9467dbb2e61f5eb0491d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_49df4db8c8eb490885f1dee5a46e001f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7360/7360 [01:49&lt;00:00, 67.21it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cae4f9922cc24c62994a6d8ddc45ba2f"
          }
        },
        "87e2f11c782d48b0885d7db9151908e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77dfbcedf5224ae9847aaf7e7268b9a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49df4db8c8eb490885f1dee5a46e001f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cae4f9922cc24c62994a6d8ddc45ba2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd7mm9zU1tHX"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtHcejFIVVpD"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiMrkOjeWj1A"
      },
      "source": [
        "# unzip files to main content directory:\n",
        "! unzip -q drive/MyDrive/cisc873-dm-f20-a4/img_test.zip\n",
        "! unzip -q drive/MyDrive/cisc873-dm-f20-a4/img_train.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hZsGc0Z1Ani"
      },
      "source": [
        "import collections\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from pprint import pprint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.notebook import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Bidirectional, GRU, Attention, Concatenate, Embedding, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjJ5AcKB1xZk"
      },
      "source": [
        "# Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEur8cLCR1Zk"
      },
      "source": [
        "# Load in train and test data to dataframes\n",
        "xy_train_df = pd.read_csv('drive/MyDrive/cisc873-dm-f20-a4/train_xy.csv')\n",
        "x_test_df = pd.read_csv('drive/MyDrive/cisc873-dm-f20-a4/test_x.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NGojpH_R1Zl"
      },
      "source": [
        "# preprocess image data\n",
        "def load_image(file):\n",
        "    try:\n",
        "        # Opening image file, convert to greyscale and resizing\n",
        "        image = Image.open(\n",
        "            file\n",
        "        ).convert('LA').resize((64, 64))\n",
        "        # make image into numpy array\n",
        "        arr = np.array(image) \n",
        "    except:\n",
        "        # If the image isn't fine, make array of 0s\n",
        "        arr = np.zeros((64, 64, 2))\n",
        "    return arr\n",
        "\n",
        "# loading images from directory listed in xy_train.csv:\n",
        "x_image = np.array([load_image(i) for i in tqdm(xy_train_df.image)])\n",
        "\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_text = xy_train_df.summary.astype('str')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyvZiXfMx6RR"
      },
      "source": [
        "# check image loading\n",
        "plt.imshow(x_image[0, :, :, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z3FEfYsR1Zm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc59bdc6-00e0-4a7b-9502-6fe0b3b49ce5"
      },
      "source": [
        "# labels:\n",
        "y_price = xy_train_df.price\n",
        "# Convert types to categories for listing type\n",
        "y_type = xy_train_df.type.astype('category').cat.codes\n",
        "\n",
        "# Display number of price and type categories\n",
        "len_price = len(y_price.unique())\n",
        "len_type = len(y_type.unique())\n",
        "print('unique values for price category', len_price, y_price.unique())\n",
        "print('unique values for type category', len_type, y_type.unique())\n",
        "\n",
        "# splitting:\n",
        "x_tr_image, x_vl_image, x_tr_text, x_vl_text, y_tr_price, y_vl_price, y_tr_type, y_vl_type = train_test_split(\n",
        "    x_image, \n",
        "    x_text,\n",
        "    y_price,\n",
        "    y_type,\n",
        "    test_size=0.2)\n",
        "\n",
        "print(np.shape(x_tr_image))\n",
        "print(np.shape(x_vl_image))\n",
        "print(np.shape(y_tr_price))\n",
        "print(np.shape(y_vl_price))\n",
        "print(np.shape(y_tr_type))\n",
        "print(np.shape(y_vl_type))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique values for price category 3 [1 0 2]\n",
            "unique values for type category 24 [ 1 17 22 10 18 20  5  2  8  4 23 13 15 16 14 11 19  0 21  3  6 12  7  9]\n",
            "(6101, 64, 64, 2)\n",
            "(1526, 64, 64, 2)\n",
            "(6101,)\n",
            "(1526,)\n",
            "(6101,)\n",
            "(1526,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU7cvJnl10c-"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqTbsSmnxih3"
      },
      "source": [
        "## Template Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh70MnCDR1Zm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aed9cc0-d489-422e-cf0d-780c9896aa91"
      },
      "source": [
        "# preprocess text data\n",
        "# maximum number of common words to keep in tokenizer\n",
        "vocab_size = 40000\n",
        "# maximum sequence length for padding/truncating\n",
        "max_len = 100\n",
        "\n",
        "\n",
        "# build vocabulary from training set\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(x_tr_text)\n",
        "\n",
        "\n",
        "def _preprocess(list_of_text):\n",
        "    # truncate or pad sequences to max_len\n",
        "    return pad_sequences(\n",
        "        tokenizer.texts_to_sequences(list_of_text),\n",
        "        maxlen=max_len,\n",
        "        padding='post', # padding with 0s at the end of the sequence\n",
        "    )\n",
        "    \n",
        "\n",
        "# padding is done inside: \n",
        "x_tr_text_id = _preprocess(x_tr_text)\n",
        "x_vl_text_id = _preprocess(x_vl_text)\n",
        "\n",
        "print(x_tr_text_id.shape) \n",
        "print(x_vl_text_id.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6101, 100)\n",
            "(1526, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5E5zYSiR1Zm"
      },
      "source": [
        "# Visually confirming tokenizer worked\n",
        "pprint(tokenizer.sequences_to_texts(x_tr_text_id[:5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75tmwBWAR1Zm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f87bd8c-9080-4e0d-c031-c8830e96b104"
      },
      "source": [
        "print('total words in the dictionary:', tokenizer.num_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total words in the dictionary: 40000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIG1nNboVpmC"
      },
      "source": [
        "## Advanced Tokenizer\n",
        "\n",
        "Swap the original tokenizer with the sentencepiece tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS7ZUgr0WU_S"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lezzkRBVwQW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e445552f-0c80-4d0d-e3be-2719caada342"
      },
      "source": [
        "import sentencepiece as spm\n",
        "import io\n",
        "\n",
        "# maximum number of common words to keep in tokenizer \n",
        "# Note: this value changes. Can set to 40,000 and update based on received error message\n",
        "sp_vocab_size = 13180\n",
        "# maximum sequence length for padding/truncating\n",
        "max_len = 100\n",
        "\n",
        "# binary stream using an in-memory bytes buffer to write model\n",
        "token_model = io.BytesIO()\n",
        "\n",
        "# Train SentencePiece Model\n",
        "# Training with an iterable version of the train text, writing model to token_model with a maximum of sp_vocab_size words\n",
        "spm.SentencePieceTrainer.train(sentence_iterator=iter(x_tr_text), model_writer=token_model, vocab_size=sp_vocab_size)\n",
        "\n",
        "# Write trained model to out.model \n",
        "with open('out.model', 'wb') as f:\n",
        "    f.write(token_model.getvalue())\n",
        "\n",
        "# Make processor for encoding \n",
        "sp=spm.SentencePieceProcessor(model_proto=token_model.getvalue())\n",
        "\n",
        "def sentence_preprocess(list_of_text):\n",
        "    return pad_sequences(\n",
        "        # Encoding text into sentence pieces/ids\n",
        "        sp.encode((list_of_text)),\n",
        "        maxlen=max_len,\n",
        "        padding='post'\n",
        "    )\n",
        "\n",
        "# padding is done inside:\n",
        "# Convert train and validation text from Series to list for sp encoding\n",
        "x_tr_text_sent_id = sentence_preprocess(x_tr_text.tolist())\n",
        "x_vl_text_sent_id = sentence_preprocess(x_vl_text.tolist())\n",
        "\n",
        "print(x_tr_text_sent_id.shape)\n",
        "print(x_vl_text_sent_id.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6101, 100)\n",
            "(1526, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Sb8y2j2tRt_"
      },
      "source": [
        "# Confirm encoding worked\n",
        "sp.decode(x_tr_text_sent_id[:5].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMrwkVvOxDE0",
        "outputId": "f9c4b984-0716-43fe-9977-f163a5e39de2"
      },
      "source": [
        "print('total words in the dictionary:', vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total words in the dictionary: 13110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00_UJKS9172N"
      },
      "source": [
        "# Model Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu0gfbqiK68c"
      },
      "source": [
        "## Template Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QkkRmqYR1Zm"
      },
      "source": [
        "# Sample Model - model provided in template from Professor Ding\n",
        "# Input text layer\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # [None, max_len]\n",
        "# Input image layer\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # [None, 64, 64, 2]\n",
        "\n",
        "# text part\n",
        "# Embedding layer for text data\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # [None, max_len, 100]\n",
        "# Reducing to 2D for fusion\n",
        "averaged = tf.reduce_mean(embedded, axis=1) # [None, 100]\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (16, 16))(in_image) # [None, 49, 49, 32]\n",
        "pl = MaxPool2D((16, 16))(cov) # [None, 3, 3, 32]\n",
        "# Reducing to 2d for fusion\n",
        "flattened = Flatten()(pl) # [None, 288]\n",
        "\n",
        "# fusion: by concatenating the image and text sections\n",
        "fused = tf.concat([averaged, flattened], axis=-1) # [None, 388]\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # [None, 3]\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # [None, 24]\n",
        "\n",
        "# Build the model\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    },\n",
        "    name=\"template_model\"\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(),\n",
        "    # Using sparse categorical cross entropy for loss function since there are more than two label classes\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    # Loss weights are coefficients to weight the loss contributions of different model outputs. \n",
        "    # The loss value that will be minimized by the model will then be the weighted\n",
        "    # sum of all individual losses, weighted by the loss_weights coefficients.\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    # Metrics to be evaluated by the model during training and testing \n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "# Display info about model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuVfhTpW2ans"
      },
      "source": [
        "## Text Layers\n",
        "\n",
        "Swap the original reduce_mean layer with a BiDirectional GRU layer, and use Attention to aggregate the time dimension (see lecture notes for API & Examples).\n",
        "\n",
        "Following example in documentation Keras Attention API documentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY2mKaBzL8j3"
      },
      "source": [
        "# Input text layer\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # [None, max_len]\n",
        "# Input image layer\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # [None, 64, 64, 2]\n",
        "\n",
        "### TEXT PART ###\n",
        "embedding = Embedding(tokenizer.num_words, 100)(in_text) # [None, max_len, 100]\n",
        "\n",
        "# Replace reduce_mean layer with BiDirectional GRU\n",
        "query_x = Bidirectional(GRU(32, return_sequences=True))(embedding) # [None, max_len, 64]\n",
        "value_x = Bidirectional(GRU(32, return_sequences=True))(embedding) # [None, max_len, 64]\n",
        "\n",
        "# Use Attention to aggregate time dimension\n",
        "fixed_query_x = tf.expand_dims(query_x[:, -1, :], [1]) # [None, 1, 64]\n",
        "# Not passing in key since it would be equivalent to value and Attention makes key equivalent by default\n",
        "query_value_attention_seq = Attention()([fixed_query_x, value_x]) # [None, 1, 64]\n",
        "# Reducing to 2D for fusion layer\n",
        "text_final = tf.squeeze(query_value_attention_seq, [1]) # [None, 64]\n",
        "\n",
        "### IMAGE PART ###\n",
        "cov = Conv2D(32, (16, 16))(in_image) # [None, 49, 49, 32]\n",
        "pl = MaxPool2D((16, 16))(cov) # [None, 3, 3, 32]\n",
        "flattened = Flatten()(pl) # [None, 288]\n",
        "\n",
        "# fusion:\n",
        "fused = Concatenate()([text_final, flattened]) # [None, 352]\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # [None, 3]\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # [None, 24]\n",
        "\n",
        "# Build the model\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image,\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    },\n",
        "    name=\"text_layers_model\"\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(),\n",
        "    # Sparse categorical cross entropy: Use this crossentropy loss function when\n",
        "    # there are two or more label classes\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    # coefficients to weight the loss contributions of different model outputs. \n",
        "    # The loss value that will be minimized by the model will then be the weighted\n",
        "    # sum of all individual losses, weighted by the loss_weights coefficients.\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    # metrics to be evaluated by the model during training and testing\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "# Display info about model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McbFyHvMpbVa"
      },
      "source": [
        "## Image Layers\n",
        "\n",
        "The original layers for image contain one convolution layer. Customizing those layers and addding drop out layer for regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4UnzNFzpWEM"
      },
      "source": [
        "# Input text layer\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # [None, max_len]\n",
        "# Input image layer\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # [None, 64, 64, 2]\n",
        "\n",
        "### TEXT PART ###\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # [None, max_len, 100]\n",
        "averaged = tf.reduce_mean(embedded, axis=1) # [None, 100]\n",
        "\n",
        "### IMAGE PART ###\n",
        "# VERSION 1\n",
        "x = Conv2D(32, (16, 16))(in_image) # [None, 49, 49, 32]\n",
        "x = Conv2D(32, (16, 16))(x) # [None, 34, 34, 32]\n",
        "pl = MaxPool2D((16, 16))(x) # [None, 2, 2, 32]\n",
        "img_final = Flatten()(pl) # [None, 128]\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([averaged, img_final], axis=-1) # [None, 228]\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # [None, 3]\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # [None, 24]\n",
        "\n",
        "# Build the model\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    },\n",
        "    name=\"image_layers_model_v1\"\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(),\n",
        "    # Sparse categorical cross entropy: Use this crossentropy loss function when\n",
        "    # there are two or more label classes\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    # coefficients to weight the loss contributions of different model outputs. \n",
        "    # The loss value that will be minimized by the model will then be the weighted\n",
        "    # sum of all individual losses, weighted by the loss_weights coefficients.\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    # metrics to be evaluated by the model during training and testing\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "# Display info about model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_XdcADZpb-O"
      },
      "source": [
        "## Fusion Layer\n",
        "\n",
        "Replacing concatenation fusion with different approaches. First reduce mean and then reduce sum.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alZe1O6PWq4Z"
      },
      "source": [
        "### Reduce Mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQztjse93cPG"
      },
      "source": [
        "# Sample model with fusion layer as reduce mean\n",
        "# Input text layer\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # [None, max_len]\n",
        "# Input image layer\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # [None, 64, 64, 2]\n",
        "\n",
        "### TEXT PART ###\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # [None, max_len, 100]\n",
        "averaged = tf.reduce_mean(embedded, axis=1) # [None, 100]\n",
        "text_final = Dense(64)(averaged) # [None, 64]\n",
        "\n",
        "\n",
        "### IMAGE PART ###\n",
        "cov = Conv2D(32, (16, 16))(in_image) # [None, 49, 49, 32]\n",
        "pl = MaxPool2D((16, 16))(cov) # [None, 3, 3, 32]\n",
        "flattened = Flatten()(pl) # [None, 288]\n",
        "img_final = Dense(64)(flattened) # [None, 64]\n",
        "\n",
        "### FUSION ### \n",
        "fused = tf.reduce_mean([text_final, img_final], axis=0) # [None, 64]\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # [None, 3]\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # [None, 24]\n",
        "\n",
        "# Build the model\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    },\n",
        "    name=\"reducemean_fusion_model\"\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(),\n",
        "    # Sparse categorical cross entropy: Use this crossentropy loss function when\n",
        "    # there are two or more label classes\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    # coefficients to weight the loss contributions of different model outputs. \n",
        "    # The loss value that will be minimized by the model will then be the weighted\n",
        "    # sum of all individual losses, weighted by the loss_weights coefficients.\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    # metrics to be evaluated by the model during training and testing\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "# Display info about model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ0uRNKIWsZC"
      },
      "source": [
        "### Reduce Sum "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh14n2ZlR6Yo"
      },
      "source": [
        "# Sample model with fusion layer changed to reduce sum\n",
        "# Input text layer\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # [None, max_len]\n",
        "# Input image layer\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # [None, 64, 64, 2]\n",
        "\n",
        "### TEXT PART ###\n",
        "embedded = keras.layers.Embedding(tokenizer.num_words, 100)(in_text) # [None, max_len, 100]\n",
        "averaged = tf.reduce_mean(embedded, axis=1) # [None, 100]\n",
        "txt_final = Dense(64)(averaged) # [None, 64]\n",
        "\n",
        "### IMAGE PART ###\n",
        "cov = Conv2D(32, (16, 16))(in_image) # [None, 49, 49, 32]\n",
        "pl = MaxPool2D((16, 16))(cov) # [None, 3, 3, 32]\n",
        "flattened = Flatten()(pl) # [None, 288]\n",
        "img_final = Dense(64)(flattened) # [None, 64]\n",
        "\n",
        "### FUSION ###\n",
        "fused = tf.reduce_sum([txt_final, img_final], axis=0) # [None, 64]\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # [None, 3]\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # [None, 24]\n",
        "\n",
        "# Build the model\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    },\n",
        "    name=\"reducesum_fusion_model\"\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(),\n",
        "    # Sparse categorical cross entropy: Use this crossentropy loss function when\n",
        "    # there are two or more label classes\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    # coefficients to weight the loss contributions of different model outputs. \n",
        "    # The loss value that will be minimized by the model will then be the weighted\n",
        "    # sum of all individual losses, weighted by the loss_weights coefficients.\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    # metrics to be evaluated by the model during training and testing\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "# Display info about model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jZYe5-fmJK_"
      },
      "source": [
        "## Advanced Tokenizer\n",
        "\n",
        "Swap the original tokenizer with the sentencepiece tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIrMFbR_mH4-"
      },
      "source": [
        "# Sample Model - model provided in template from Professor Ding\n",
        "# Input text layer\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # [None, max_len]\n",
        "# Input image layer\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # [None, 64, 64, 2]\n",
        "\n",
        "# text part\n",
        "embedded = keras.layers.Embedding(vocab_size, 100)(in_text) # [None, max_len, 100]\n",
        "averaged = tf.reduce_mean(embedded, axis=1) # [None, 100]\n",
        "\n",
        "# image part\n",
        "cov = Conv2D(32, (16, 16))(in_image) # [None, 49, 49, 32]\n",
        "pl = MaxPool2D((16, 16))(cov) # [None, 3, 3, 32]\n",
        "flattened = Flatten()(pl) # [None, 288]\n",
        "\n",
        "# fusion:\n",
        "fused = tf.concat([averaged, flattened], axis=-1) # [None, 388]\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # [None, 3]\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # [None, 24]\n",
        "\n",
        "# Build the model\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    },\n",
        "    name=\"advancedtokenizer_model\"\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(),\n",
        "    # Sparse categorical cross entropy: Use this crossentropy loss function when\n",
        "    # there are two or more label classes\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    # coefficients to weight the loss contributions of different model outputs. \n",
        "    # The loss value that will be minimized by the model will then be the weighted\n",
        "    # sum of all individual losses, weighted by the loss_weights coefficients.\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    # metrics to be evaluated by the model during training and testing\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "# Display info about model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_G9KqY7LfLHP"
      },
      "source": [
        "## Putting it all together\n",
        "\n",
        "Combining the model updates from the above sections into one model to tune."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le1z5oyZfUdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eed327b-176d-4908-9ce1-41b436788dac"
      },
      "source": [
        "# VERSION 1\n",
        "# Input text layer\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # [None, max_len]\n",
        "# Input image layer\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # [None, 64, 64, 2]\n",
        "\n",
        "### TEXT PART ###\n",
        "# Keras tokenizer\n",
        "embedding = Embedding(tokenizer.num_words, 100)(in_text) # [None, max_len, 100]\n",
        "\n",
        "# Sentencepiece tokenizer\n",
        "# embedding = Embedding(sp_vocab_size, 100)(in_text) # [None, max_len, 100]\n",
        "\n",
        "# Replace reduce_mean layer with BiDirectional GRU\n",
        "query_x = Bidirectional(GRU(32, return_sequences=True))(embedding) # [None, max_len, 64]\n",
        "value_x = Bidirectional(GRU(32, return_sequences=True))(embedding) # [None, max_len, 64]\n",
        "\n",
        "# Use Attention to aggregate time dimension\n",
        "fixed_query_x = tf.expand_dims(query_x[:, -1, :], [1]) # [None, 1, 64]\n",
        "# Not passing in key since it would be equivalent to value and Attention makes key equivalent by default\n",
        "query_value_attention_seq = Attention()([fixed_query_x, value_x]) # [None, 1, 64]\n",
        "# Reducing to 2D for fusion layer\n",
        "squeezed = tf.squeeze(query_value_attention_seq, [1]) # [None, 64]\n",
        "text_final = Dense(64)(squeezed) # [None, 64]\n",
        "\n",
        "### IMAGE PART ###\n",
        "x = Conv2D(32, (16, 16))(in_image) # [None, 49, 49, 32]\n",
        "x = Conv2D(32, (16, 16))(x) # [None, 34, 34, 32]\n",
        "pl = MaxPool2D((16, 16))(x) # [None, 2, 2, 32]\n",
        "flattened = Flatten()(pl) # [None, 128]\n",
        "img_final = Dense(64)(flattened) # [None, 64]\n",
        "\n",
        "### FUSION ### \n",
        "# Reduce Mean fusion\n",
        "fused = tf.reduce_mean([text_final, img_final], axis=0) # [None, 64]\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # [None, 3]\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # [None, 24]\n",
        "\n",
        "# Build the model\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    },\n",
        "    name=\"keras_alltogether_model1\"\n",
        "    # name=\"sp_alltogether_model1\"\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(),\n",
        "    # Sparse categorical cross entropy: Use this crossentropy loss function when\n",
        "    # there are two or more label classes\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    # coefficients to weight the loss contributions of different model outputs. \n",
        "    # The loss value that will be minimized by the model will then be the weighted\n",
        "    # sum of all individual losses, weighted by the loss_weights coefficients.\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    # metrics to be evaluated by the model during training and testing\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "# Display info about model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"keras_alltogether_model1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 100, 100)     4000000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   (None, 100, 64)      25728       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 64, 64, 2)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 64)]         0           bidirectional[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 49, 49, 32)   16416       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims (TensorF [(None, 1, 64)]      0           tf_op_layer_strided_slice[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) (None, 100, 64)      25728       embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 34, 34, 32)   262176      conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention (Attention)           (None, 1, 64)        0           tf_op_layer_ExpandDims[0][0]     \n",
            "                                                                 bidirectional_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 2, 2, 32)     0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze (TensorFlow [(None, 64)]         0           attention[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 128)          0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 64)           4160        tf_op_layer_Squeeze[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           8256        flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean/input (TensorF [(2, None, 64)]      0           dense[0][0]                      \n",
            "                                                                 dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean (TensorFlowOpL [(None, 64)]         0           tf_op_layer_Mean/input[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "price (Dense)                   (None, 3)            195         tf_op_layer_Mean[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "type (Dense)                    (None, 24)           1560        tf_op_layer_Mean[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 4,344,219\n",
            "Trainable params: 4,344,219\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M144Re6yqjGb",
        "outputId": "4286b35e-b8e7-4da2-8f70-59dccb8cc78a"
      },
      "source": [
        "# VERSION 2\n",
        "# Input text layer\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # [None, max_len]\n",
        "# Input image layer\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # [None, 64, 64, 2]\n",
        "\n",
        "### TEXT PART ###\n",
        "# Keras tokenizer\n",
        "embedding = Embedding(tokenizer.num_words, 100)(in_text) # [None, max_len, 100]\n",
        "\n",
        "# Sentencepiece tokenizer\n",
        "# embedding = Embedding(sp_vocab_size, 100)(in_text) # [None, max_len, 100]\n",
        "\n",
        "# Replace reduce_mean layer with BiDirectional GRU\n",
        "gru = Bidirectional(GRU(16, return_sequences=True))(embedding) # [None, max_len, 32]\n",
        "query_x = Bidirectional(GRU(8, return_sequences=True))(gru) # [None, max_len, 16]\n",
        "value_x = Bidirectional(GRU(8, return_sequences=True))(gru) # [None, max_len, 16]\n",
        "\n",
        "# Use Attention to aggregate time dimension\n",
        "fixed_query_x = tf.expand_dims(query_x[:, -1, :], [1]) # [None, 1, 16]\n",
        "# Not passing in key since it would be equivalent to value and Attention makes key equivalent by default\n",
        "query_value_attention_seq = Attention()([fixed_query_x, value_x]) # [None, 1, 16]\n",
        "# Reducing to 2D for fusion layer\n",
        "squeezed = tf.squeeze(query_value_attention_seq, [1]) # [None, 16]\n",
        "text_final = Dense(16)(squeezed) # [None, 16]\n",
        "\n",
        "### IMAGE PART ###\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(in_image) # [None, 64, 64, 8]\n",
        "pl = MaxPool2D((2, 2))(x) # [None, 32, 32, 8]\n",
        "flattened = Flatten()(pl) # [None, 8192]\n",
        "img_final = Dense(16)(flattened) # [None, 16]\n",
        "\n",
        "### FUSION ### \n",
        "# Reduce Mean fusion\n",
        "fused = tf.reduce_mean([text_final, img_final], axis=0) # [None, 16]\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # [None, 3]\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # [None, 24]\n",
        "\n",
        "# Build the model\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    },\n",
        "    name=\"keras_alltogether_model2\"\n",
        "    # name=\"sp_alltogether_model2\"\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(),\n",
        "    # Sparse categorical cross entropy: Use this crossentropy loss function when\n",
        "    # there are two or more label classes\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    # coefficients to weight the loss contributions of different model outputs. \n",
        "    # The loss value that will be minimized by the model will then be the weighted\n",
        "    # sum of all individual losses, weighted by the loss_weights coefficients.\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    # metrics to be evaluated by the model during training and testing\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "# Display info about model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"keras_alltogether_model2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 100, 100)     4000000     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 100, 32)      11328       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 100, 16)      2016        bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_1 (Te [(None, 16)]         0           bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 64, 64, 2)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_1 (Tenso [(None, 1, 16)]      0           tf_op_layer_strided_slice_1[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) (None, 100, 16)      2016        bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 8)    152         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_1 (Attention)         (None, 1, 16)        0           tf_op_layer_ExpandDims_1[0][0]   \n",
            "                                                                 bidirectional_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 8)    0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_1 (TensorFl [(None, 16)]         0           attention_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 8192)         0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 16)           272         tf_op_layer_Squeeze_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 16)           131088      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_1/input (Tenso [(2, None, 16)]      0           dense_2[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_1 (TensorFlowO [(None, 16)]         0           tf_op_layer_Mean_1/input[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "price (Dense)                   (None, 3)            51          tf_op_layer_Mean_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "type (Dense)                    (None, 24)           408         tf_op_layer_Mean_1[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 4,147,331\n",
            "Trainable params: 4,147,331\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76r-ZH_D6I6g",
        "outputId": "8353b288-c427-4f3d-d4ed-1179bdff1bf6"
      },
      "source": [
        "# VERSION 3\n",
        "# Input text layer\n",
        "in_text = keras.Input(batch_shape=(None, max_len)) # [None, max_len]\n",
        "# Input image layer\n",
        "in_image = keras.Input(batch_shape=(None, 64, 64, 2)) # [None, 64, 64, 2]\n",
        "\n",
        "### TEXT PART ###\n",
        "# Keras tokenizer\n",
        "embedding = Embedding(tokenizer.num_words, 100)(in_text) # [None, max_len, 100]\n",
        "\n",
        "# Sentencepiece tokenizer\n",
        "# embedding = Embedding(sp_vocab_size, 100)(in_text) # [None, max_len, 100]\n",
        "\n",
        "# Replace reduce_mean layer with BiDirectional GRU\n",
        "gru = Bidirectional(GRU(16, return_sequences=True))(embedding) # [None, max_len, 32]\n",
        "query_x = Bidirectional(GRU(8, return_sequences=True))(gru) # [None, max_len, 16]\n",
        "value_x = Bidirectional(GRU(8, return_sequences=True))(gru) # [None, max_len, 16]\n",
        "\n",
        "# Use Attention to aggregate time dimension\n",
        "fixed_query_x = tf.expand_dims(query_x[:, -1, :], [1]) # [None, 1, 16]\n",
        "# Not passing in key since it would be equivalent to value and Attention makes key equivalent by default\n",
        "query_value_attention_seq = Attention()([fixed_query_x, value_x]) # [None, 1, 16]\n",
        "# Reducing to 2D for fusion layer\n",
        "squeezed = tf.squeeze(query_value_attention_seq, [1]) # [None, 16]\n",
        "text_final = Dense(16)(squeezed) # [None, 16]\n",
        "\n",
        "### IMAGE PART ###\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='same')(in_image) # [None, 64, 64, 8]\n",
        "x = Dropout(0.3)(x) # [None, 64, 64, 8]\n",
        "x = Conv2D(8, (3, 3), activation='relu', padding='valid')(x) # [None, 62, 62, 8]\n",
        "x = Dropout(0.3)(x) # [None, 62, 62, 8]\n",
        "pl = MaxPool2D((2, 2))(x) # [None, 31, 31, 8]\n",
        "flattened = Flatten()(pl) # [None, 7688]\n",
        "img_final = Dense(16)(flattened) # [None, 16]\n",
        "\n",
        "### FUSION ### \n",
        "# Reduce Mean fusion\n",
        "fused = tf.reduce_mean([text_final, img_final], axis=0) # [None, 16]\n",
        "\n",
        "# multi-objectives (each is a multi-class classification)\n",
        "p_price = Dense(len_price, activation='softmax', name='price')(fused) # [None, 3]\n",
        "p_type = Dense(len_type, activation='softmax', name='type')(fused) # [None, 24]\n",
        "\n",
        "# Build the model\n",
        "model = keras.Model(\n",
        "    inputs={\n",
        "        'summary': in_text,\n",
        "        'image': in_image\n",
        "    },\n",
        "    outputs={\n",
        "        'price': p_price,\n",
        "        'type': p_type,\n",
        "    },\n",
        "    name=\"keras_alltogether_model3\"\n",
        "    # name=\"sp_alltogether_model3\"\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(),\n",
        "    # Sparse categorical cross entropy: Use this crossentropy loss function when\n",
        "    # there are two or more label classes\n",
        "    loss={\n",
        "        'price': 'sparse_categorical_crossentropy',\n",
        "        'type': 'sparse_categorical_crossentropy',\n",
        "    },\n",
        "    # coefficients to weight the loss contributions of different model outputs. \n",
        "    # The loss value that will be minimized by the model will then be the weighted\n",
        "    # sum of all individual losses, weighted by the loss_weights coefficients.\n",
        "    loss_weights={\n",
        "        'price': 0.5,\n",
        "        'type': 0.5,       \n",
        "    },\n",
        "    # metrics to be evaluated by the model during training and testing\n",
        "    metrics={\n",
        "        'price': ['SparseCategoricalAccuracy'],\n",
        "        'type': ['SparseCategoricalAccuracy'],\n",
        "    },\n",
        ")\n",
        "\n",
        "# Display info about model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"keras_alltogether_model3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 100, 100)     4000000     input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 64, 64, 2)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) (None, 100, 32)      11328       embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 64, 64, 8)    152         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) (None, 100, 16)      2016        bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 64, 64, 8)    0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_2 (Te [(None, 16)]         0           bidirectional_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 62, 62, 8)    584         dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_ExpandDims_2 (Tenso [(None, 1, 16)]      0           tf_op_layer_strided_slice_2[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_7 (Bidirectional) (None, 100, 16)      2016        bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 62, 62, 8)    0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "attention_2 (Attention)         (None, 1, 16)        0           tf_op_layer_ExpandDims_2[0][0]   \n",
            "                                                                 bidirectional_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 31, 31, 8)    0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_2 (TensorFl [(None, 16)]         0           attention_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 7688)         0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 16)           272         tf_op_layer_Squeeze_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 16)           123024      flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_2/input (Tenso [(2, None, 16)]      0           dense_4[0][0]                    \n",
            "                                                                 dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mean_2 (TensorFlowO [(None, 16)]         0           tf_op_layer_Mean_2/input[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "price (Dense)                   (None, 3)            51          tf_op_layer_Mean_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "type (Dense)                    (None, 24)           408         tf_op_layer_Mean_2[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 4,139,851\n",
            "Trainable params: 4,139,851\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHIZLVt52Af4"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAvq8NM-zRFX"
      },
      "source": [
        "## With template tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyVFF4LTR1Zm"
      },
      "source": [
        "# Fitting model to training data\n",
        "print(\"Training: \" + model.name)\n",
        "epochs = 20             # Number of forward and backward passes to perform through network \n",
        "batch_size = 32         # Number of training examples to use in one iteration\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_id,\n",
        "        'image': x_tr_image,\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price,\n",
        "        'type': y_tr_type,\n",
        "    },\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_id,\n",
        "            'image': x_vl_image\n",
        "         }, \n",
        "        {\n",
        "            'price': y_vl_price,\n",
        "            'type': y_vl_type,\n",
        "        }),\n",
        "    # Early stopping used to try to prevent overfitting\n",
        "    # Patience stops training after 5 epochs with no improvement in validation loss for price prediction\n",
        "    # restore_best_weights puts weights back to epoch with best value of val_price_loss\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, restore_best_weights=True)\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihrh1vTrziYk"
      },
      "source": [
        "# Generate plots to visually evaluate training and validation for price accuracy\n",
        "plt.plot(history.history['price_sparse_categorical_accuracy'])\n",
        "plt.plot(history.history['val_price_sparse_categorical_accuracy'])\n",
        "plt.title('model accuracy - ' + model.name)\n",
        "plt.ylabel('Price Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tyT3vG8zWjN"
      },
      "source": [
        "## With advanced tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNanFMOTzfh7"
      },
      "source": [
        "# Fitting model to training data\n",
        "print(\"Training: \" + model.name)\n",
        "epochs = 20             # Number of forward and backward passes to perform through network \n",
        "batch_size = 32         # Number of training examples to use in one iteration\n",
        "history = model.fit(\n",
        "    x={\n",
        "        'summary': x_tr_text_sent_id,\n",
        "        'image': x_tr_image,\n",
        "    },\n",
        "    y={\n",
        "        'price': y_tr_price,\n",
        "        'type': y_tr_type,\n",
        "    },\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(\n",
        "        {\n",
        "            'summary': x_vl_text_sent_id,\n",
        "            'image': x_vl_image\n",
        "         }, \n",
        "        {\n",
        "            'price': y_vl_price,\n",
        "            'type': y_vl_type,\n",
        "        }),\n",
        "    # Early stopping used to try to prevent overfitting\n",
        "    # Patience stops training after 5 epochs with no improvement in validation loss for price prediction\n",
        "    # restore_best_weights puts weights back to epoch with best value of val_price_loss\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_price_loss', patience=5, restore_best_weights=True)\n",
        "    ],\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkSB5FwKepK0"
      },
      "source": [
        "# Generate plots to visually evaluate training and validation for price accuracy\n",
        "plt.plot(history.history['price_sparse_categorical_accuracy'])\n",
        "plt.plot(history.history['val_price_sparse_categorical_accuracy'])\n",
        "plt.title('model accuracy - ' + model.name)\n",
        "plt.ylabel('Price Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOruURyR2Hbf"
      },
      "source": [
        "# Model Testing and Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "164182fe6aed4ba68c567a0e3914fab8",
            "77d639ca2913440885008a08dddd5aeb",
            "9dc601469c85439f90d72ab941c44c84",
            "cb33613314e9467dbb2e61f5eb0491d6",
            "87e2f11c782d48b0885d7db9151908e4",
            "77dfbcedf5224ae9847aaf7e7268b9a3",
            "49df4db8c8eb490885f1dee5a46e001f",
            "cae4f9922cc24c62994a6d8ddc45ba2f"
          ]
        },
        "id": "6fxoXMDER1Zm",
        "outputId": "96cc3db2-4186-4eda-faff-4f4d9f283521"
      },
      "source": [
        "# Preprocess test image data\n",
        "x_test_image = np.array([load_image(i) for i in tqdm(x_test_df.image)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "164182fe6aed4ba68c567a0e3914fab8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=7360.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keZlt5s705qD"
      },
      "source": [
        "## With template tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoqKB--AZYgc"
      },
      "source": [
        "# Preprocess test text data using template tokenizer\n",
        "# loading summary: (force convert some of the non-string cell to string)\n",
        "x_test_summary = _preprocess(x_test_df.summary.astype(str))\n",
        "\n",
        "# Run test data through trained network\n",
        "y_predict = model.predict(\n",
        "    {\n",
        "        'summary': x_test_summary,\n",
        "        'image': x_test_image\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price']\n",
        "print(price_predicted)\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1)\n",
        "print(price_category_predicted)\n",
        "\n",
        "# Setup file name as \"modelname_epochcount_batchsize.csv\" (ex \"model1_10_16.csv\") in my Results folder on Google Drive\n",
        "output_name = \"drive/MyDrive/cisc873-dm-f20-a4/Results/\" + model.name + \"_\" + str(history.epoch[-1]) + \"_\" + str(batch_size) + \".csv\"\n",
        "\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv(output_name, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_BElqI208nM"
      },
      "source": [
        "## With advanced tokenizer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPYYPb6D03DF"
      },
      "source": [
        "# Using sentencepiece tokenizer\n",
        "# loading summary: (force convert some of the non-string cell to string) \n",
        "# Convert test text from Series to list for sp encoding\n",
        "x_test_sent_summary = sentence_preprocess(x_test_df.summary.astype(str).tolist())\n",
        "\n",
        "# Run test data through trained network\n",
        "y_predict = model.predict(\n",
        "    {\n",
        "        'summary': x_test_sent_summary,\n",
        "        'image': x_test_image\n",
        "    }\n",
        ")\n",
        "\n",
        "price_predicted = y_predict['price']\n",
        "print(price_predicted)\n",
        "price_category_predicted = np.argmax(price_predicted, axis=1)\n",
        "print(price_category_predicted)\n",
        "\n",
        "output_name = \"drive/MyDrive/cisc873-dm-f20-a4/Results/\" + model.name + \"_sent_token_\" + str(history.epoch[-1]) + \"_\" + str(batch_size) + \".csv\"\n",
        "\n",
        "pd.DataFrame(\n",
        "    {'id': x_test_df.id,\n",
        "     'price': price_category_predicted}).to_csv(output_name, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}